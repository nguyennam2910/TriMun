{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BXdX7IBKf71g"
   },
   "source": [
    "# Begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 870
    },
    "colab_type": "code",
    "id": "EZ76XBGqNnP1",
    "outputId": "a9721496-3fd8-46b4-e861-0482b0839923"
   },
   "outputs": [],
   "source": [
    "## installing some packages\n",
    "!pip install mlxtend==0.17\n",
    "!pip install -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RG98Kma47LFR",
    "outputId": "5d018497-bd24-459e-c7ba-64c42ddc194c"
   },
   "outputs": [],
   "source": [
    "# save dir\n",
    "import os\n",
    "root = os.getcwd()\n",
    "print(root)\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks, convolve\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "emotion_keys = [\"No Emotion\", \"Anger\", \"Hate\", \"Grief\",\"P-Love\", \"R-Love\",\"Joy\", \"Reverence\"]\n",
    "neu_keys = [\"Neutral\", \"Negative\", \"Positive\"]\n",
    "\n",
    "results_fold = \"results/7s-overlapping\"\n",
    "fold_dir = os.path.join(root, results_fold)\n",
    "print(fold_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DIZvn7xbip58"
   },
   "outputs": [],
   "source": [
    "# function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize = False,\n",
    "                          savefig = False,\n",
    "                          figname = \"confusion_matrix.png\"):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "    savefig:      If False, do not save the figure\n",
    "                  If True, plot the figure with the given name defined by figname argument\n",
    "    figname:      name of the figure to save\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    height, width = cm.shape\n",
    "    offset = 0.5\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.hlines(y=np.arange(height+1)- offset, xmin=-offset, xmax=width-offset)\n",
    "    plt.vlines(x=np.arange(width+1) - offset, ymin=-offset, ymax=height-offset)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    cmn = 100 * cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize == True:\n",
    "            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        elif normalize == False:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\\n {:0.2f} %\".format(cm[i, j], cmn[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     verticalalignment='center',\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    # plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.2f} %; misclass={:0.2f} %'.format(100*accuracy, 100*misclass))\n",
    "\n",
    "    if savefig:\n",
    "        plt.savefig(figname, bbox_inches = \"tight\")\n",
    "        print(\"saved image to drive\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yE7zBoEwSxPe"
   },
   "outputs": [],
   "source": [
    "def segmenting_overlapping(data, slice_length = 10, overlap = 7, sampling_rate = 20):\n",
    "    # function to segment 1d vector signal\n",
    "    # data: all data -shape (N, channels, signal_length)\n",
    "    # slice_length: length of the slice in seconds\n",
    "    # overlap: length of the overlapping in seconds\n",
    "    # sampling_rate: sampling rate of the signal\n",
    "    segmented_data = []\n",
    "    data_shape = data.shape\n",
    "    len_signal = data_shape[2]\n",
    "    len_std = sampling_rate * slice_length\n",
    "    for sset in data:\n",
    "        segmented_set = []\n",
    "        for signal in sset:\n",
    "            segments_list = []\n",
    "            \n",
    "            slices = np.arange(0, int(len_signal/sampling_rate)+1, slice_length-overlap, dtype=np.int) # 26 is arbitrary\n",
    "            # print(slices)\n",
    "            for start, end in zip(slices[:-1], slices[1:]):\n",
    "                start_segment = start * sampling_rate\n",
    "                end_segment = min((end + overlap)*sampling_rate, len_signal) \n",
    "#                 print(start_audio, end_audio)\n",
    "                if end_segment-start_segment == len_std:\n",
    "                    segments_list.append(signal[start_segment:end_segment])\n",
    "            segmented_set.append(segments_list)\n",
    "            segments_list = []\n",
    "        segmented_data.append(segmented_set)\n",
    "        segmented_set = []\n",
    "    segmented_data = np.array(segmented_data)\n",
    "    return segmented_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "scdHRgLxSxPp"
   },
   "source": [
    "# features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gdGwyCesSxPq"
   },
   "outputs": [],
   "source": [
    "# Extract features from signals\n",
    "\n",
    "class Function(object):\n",
    "    \"\"\"Wraper class for funcions\"\"\"\n",
    "\n",
    "    def __init__(self, func, description=\"Simple function\", fun_type='transform'):\n",
    "        self.func = func\n",
    "        self.description = description\n",
    "        self.func_type = fun_type\n",
    "\n",
    "    def __call__(self, data):\n",
    "        return self.func(data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.func_type + \":\" + self.description\n",
    "    \n",
    "    ## statistical features\n",
    "    def calculate_statistics(self, signal):\n",
    "        # signal = signal.reshape((-1, 1))\n",
    "        mean = np.nanmean(signal)\n",
    "        median = np.median(signal, axis = 0)\n",
    "        maximum = np.max(signal, axis = 0)\n",
    "        minimum = np.min(signal, axis = 0)\n",
    "        std = np.std(signal, axis = 0)\n",
    "        variance = np.var(signal, axis = 0)\n",
    "        _range = np.ptp(signal, axis = 0)\n",
    "        skewness = scipy.stats.skew(signal, axis = 0)\n",
    "        kurtosis = scipy.stats.kurtosis(signal, axis = 0)\n",
    "        \n",
    "        return [mean, median, maximum, minimum, std, variance, _range, skewness, kurtosis]\n",
    "\n",
    "    def difference_absolute_values_mean(self, signal, different_num, round_number = 2):\n",
    "        value = 0\n",
    "        for i in range(len(signal)- different_num):\n",
    "            value += abs(signal[i+different_num] - signal[i])\n",
    "        mean_value = round(value/(len(signal) - different_num), round_number )\n",
    "\n",
    "        return mean_value\n",
    "\n",
    "\n",
    "    def normalize_zeromean_variance(self, signal, mean, std):\n",
    "        normalized_signal = (signal - mean)/(std + np.finfo(float).eps)\n",
    "\n",
    "        return normalized_signal\n",
    "    \n",
    "    def normalize_signal(self, signal):\n",
    "        mean, std = np.nanmean(signal), np.nanstd(signal)\n",
    "        normalized_signal = self.normalize_zeromean_variance(signal, mean, std)\n",
    "        \n",
    "        return normalized_signal\n",
    "    \n",
    "#     def BVP_features(signal):\n",
    "\n",
    "class FeatureExtractor(Function):\n",
    "    def __init__(self):\n",
    "        fnc = Function(self)\n",
    "        # self.all_data = all_data\n",
    "        self.features_list = []\n",
    "\n",
    "\n",
    "    def fit(self, all_data):\n",
    "        print(all_data.shape)\n",
    "        # assert self.all_data.shape[2] > self.all_data.shape[1], \"data shape must be (N, channels, data)\" \n",
    "        for signal_set in all_data:\n",
    "            features = []\n",
    "            for signal in signal_set:\n",
    "\n",
    "                statistic_features = self.calculate_statistics(signal)\n",
    "                first_diff_mean = self.difference_absolute_values_mean(signal,1)\n",
    "                second_diff_mean = self.difference_absolute_values_mean(signal, 2)\n",
    "                normalized_signal = self.normalize_signal(signal)\n",
    "                first_diff_mean_normalized = self.difference_absolute_values_mean(normalized_signal, 1)\n",
    "                second_diff_mean_normalized = self.difference_absolute_values_mean(normalized_signal, 2)\n",
    "\n",
    "                features += statistic_features\n",
    "                features.append(first_diff_mean)\n",
    "                features.append(second_diff_mean)\n",
    "                features.append(first_diff_mean_normalized)\n",
    "                features.append(second_diff_mean_normalized)        \n",
    "\n",
    "            self.features_list.append(features)\n",
    "        return np.array(self.features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Rco7Ofg9SxPg",
    "outputId": "b470ce29-ac4d-4304-a4ab-133514f5ac41"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data = np.load(\"data.npy\")\n",
    "print(data.shape)\n",
    "labels  = np.load(\"labels.npy\")\n",
    "labels_number = np.ndarray((160))\n",
    "\n",
    "# EMG = data[:, :, 0]\n",
    "# BVP = data[:, :, 1]\n",
    "# GSR = data[:, :, 2]\n",
    "# RES = data[:, :, 3]\n",
    "for i,key in enumerate(emotion_keys):\n",
    "    labels_number[np.where(labels == key)] = i\n",
    "\n",
    "# cut original data to segments using segmententing_overlapping function\n",
    "slice_length = 10 # length of the segment = 10s\n",
    "sampling_rate = 20 # sampling rate of raw signal\n",
    "overlap = 0 # overlapping ratio percentage\n",
    "\n",
    "data_cut = segmenting_overlapping(np.transpose(data, (0, 2, 1)), slice_length = slice_length, overlap = overlap, sampling_rate = sampling_rate)    \n",
    "print(\"Data_cut\", data_cut.shape)\n",
    "\n",
    "## transpose to get (160, 31, 4, 200) - (N_samples, N_segments, N_channels, segment_length) \n",
    "datax = np.transpose(data_cut, (0, 2, 1, 3))\n",
    "print(\"Datax\", datax.shape)\n",
    "## generate labels\n",
    "y = np.zeros((20, datax.shape[1]))\n",
    "labelx = y\n",
    "for i in range(1,8):\n",
    "    labelx = np.concatenate((labelx, y+i))\n",
    "\n",
    "# reshape to get data in the expected form (N_samples * N_segments, N_channels, segment_length)\n",
    "# each segment is now considered as a new sample. \n",
    "dataxx = np.reshape(datax, (-1, 4, datax.shape[3]))\n",
    "print(\"Dataxx\", dataxx.shape)\n",
    "labelxx = np.reshape(labelx, (-1))\n",
    "print(\"Labelxx\", labelxx.shape)\n",
    "print(len(list(np.where(labelxx==7))[0]))\n",
    "\n",
    "# Extracting features\n",
    "feature_list = FeatureExtractor().fit(dataxx)\n",
    "print(\"Feature\", feature_list.shape)\n",
    "\n",
    "# feature_list_original = FeatureExtractor().fit(np.transpose(data, (0, 2, 1)))\n",
    "# y_test_original = labels_number\n",
    "\n",
    "# save features\n",
    "np.save(\"Feature data/features_\" + str(overlap) + \"s.npy\", feature_list)\n",
    "np.save(\"Label/\" + str(overlap) + \"sec_labels.npy\", labelxx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pu4LP6huoZ9k"
   },
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39SICJ13SxPy"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split \n",
    "from sklearn.model_selection import LeaveOneOut,  KFold, StratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "HkZqxavpSxPz",
    "outputId": "0abb56ab-875c-4c93-d5d8-99c7521cba39"
   },
   "outputs": [],
   "source": [
    "overlap = 0\n",
    "feature_list = np.load(\"Feature data/features_\" + str(overlap) + \"s.npy\")\n",
    "labelxx = np.load(\"Label/\" + str(overlap) + \"sec_labels.npy\")\n",
    "len_data = dataxx.shape[2]\n",
    "print(feature_list.shape)\n",
    "print(len_data)\n",
    "\n",
    "next_day = (int)(labelxx.shape[0]/160)\n",
    "emo_step = (int)(labelxx.shape[0]/8)\n",
    "seg = (int)(next_day/2)\n",
    "no_sample = 1\n",
    "no_exclude = (int)((len_data - 1)/(len_data - overlap*len_data/10))\n",
    "print(\"No exclude \", no_exclude)\n",
    "\n",
    "X_features_train = feature_list[0:1]\n",
    "X_features_test = feature_list[0:1]\n",
    "y_train = labelxx[0:1]\n",
    "y_test = labelxx[0:1]\n",
    "for i in range(0, 8):\n",
    "    for j in range(0, 20):\n",
    "        X_features_train = np.concatenate((X_features_train, feature_list[emo_step*i + next_day*j: emo_step*i + next_day*j + seg - no_exclude]))\n",
    "        X_features_test = np.concatenate((X_features_test, feature_list[emo_step*i + next_day*j + seg: emo_step*i + next_day*j + seg + no_sample]))\n",
    "#         X_features_train = np.concatenate((X_features_train, feature_list[emo_step*i + next_day*j + seg + no_sample: emo_step*i + next_day*j + next_day]))     \n",
    "        X_features_train = np.concatenate((X_features_train, feature_list[emo_step*i + next_day*j + seg + no_sample + no_exclude: emo_step*i + next_day*j + next_day]))\n",
    "        \n",
    "        y_train = np.concatenate((y_train, labelxx[emo_step*i + next_day*j: emo_step*i + next_day*j + seg - no_exclude]))\n",
    "        y_test = np.concatenate((y_test, labelxx[emo_step*i + next_day*j + seg: emo_step*i + next_day*j + seg + no_sample]))\n",
    "#         y_train = np.concatenate((y_train, labelxx[emo_step*i + next_day*j + seg + no_sample: emo_step*i + next_day*j + next_day]))\n",
    "        y_train = np.concatenate((y_train, labelxx[emo_step*i + next_day*j + seg + no_sample + no_exclude: emo_step*i + next_day*j + next_day]))\n",
    "\n",
    "#         X_features_train = np.concatenate((X_features_train, feature_list[emo_step*i + next_day*j + seg + 2: emo_step*i + next_day*j + next_day]))\n",
    "#         X_features_test = np.concatenate((X_features_test, feature_list[emo_step*i + next_day*j : emo_step*i + next_day*j + seg]))\n",
    "#         y_train = np.concatenate((y_train, labelxx[emo_step*i + next_day*j + seg + 2: emo_step*i + next_day*j + next_day]))\n",
    "#         y_test = np.concatenate((y_test, labelxx[emo_step*i + next_day*j : emo_step*i + next_day*j + seg]))\n",
    "\n",
    "X_features_train = X_features_train[1:]\n",
    "X_features_test = X_features_test[1:]\n",
    "y_train = y_train[1:]\n",
    "y_test = y_test[1:]\n",
    "# standardize data\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_features_train)\n",
    "X_features_train, X_features_test = sc.transform(X_features_train), sc.transform(X_features_test)\n",
    "\n",
    "print(\"Number of train samples: \", X_features_train.shape[0])\n",
    "print(\"Number of test samples: \", X_features_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "colab_type": "code",
    "id": "zAvmKhARwCPm",
    "outputId": "351660fb-6a9c-4a02-8dca-c64015b9e2fe"
   },
   "outputs": [],
   "source": [
    "# check whether the data contains nan or infinity values\n",
    "print(np.where(np.isinf(X_features_train)))\n",
    "\n",
    "na = np.where(np.isnan(X_features_train))\n",
    "print(na)\n",
    "for i in na:\n",
    "    print(i)\n",
    "    print(np.where(np.isnan(X_features_train[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neu = [0, 7]\n",
    "pos = [4, 5, 6]\n",
    "negative = [1, 2, 3]\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i] in neu:\n",
    "        y_train[i] = 0\n",
    "    elif y_train[i] in pos:\n",
    "        y_train[i] = 2\n",
    "    else:\n",
    "        y_train[i] = 1\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] in neu:\n",
    "        y_test[i] = 0\n",
    "    elif y_test[i] in pos:\n",
    "        y_test[i] = 2\n",
    "    else:\n",
    "        y_test[i] = 1\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rfe_selector = RFE(estimator = RandomForestClassifier(), n_features_to_select = 15, step = 1)\n",
    "# rfe_selector = RFE(estimator = RandomForestClassifier(random_state = 0, n_estimators = 500, max_depth = 20), n_features_to_select = 30, step = 1)\n",
    "rfe_selector.fit(X_features_train, y_train)\n",
    "rfe_support = rfe_selector.get_support()\n",
    "\n",
    "# feat_cols = [i if rfe_support[i] is True for i in range(rfe_support.size)]\n",
    "feat_cols = []\n",
    "for i in range(rfe_support.size):\n",
    "    if rfe_support[i]:\n",
    "        feat_cols.append(i)\n",
    "# [0, 1, 4, 5, 10, 14, 15, 18, 19, 20, 22, 26, 27, 28, 29, 31, 39, 40, 42] 0%\n",
    "# [0, 1, 4, 5, 6, 10, 14, 15, 17, 18, 19, 20, 26, 27, 28, 29, 39, 40, 42] 10%\n",
    "print(feat_cols)\n",
    "\n",
    "X_train = X_features_train[:, feat_cols]\n",
    "X_test = X_features_test[:, feat_cols]\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "CM = confusion_matrix(y_test, clf.predict(X_test))\n",
    "\n",
    "fig = plot_confusion_matrix(cm  = CM,\n",
    "                      normalize    = None,\n",
    "                      target_names = emotion_keys,\n",
    "                      title        = \"Confusion Matrix - Overlapped data- RandomForest\",\n",
    "                      savefig = True,\n",
    "                      figname = \"Random Forest confusion matrix-both.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resDT = []\n",
    "resLDA = []\n",
    "for i in range(1, 53):\n",
    "    rfe_selector = RFE(estimator = DecisionTreeClassifier(), n_features_to_select = i, step = 1)\n",
    "    rfe_selector.fit(X_features_train, y_train)\n",
    "    rfe_support = rfe_selector.get_support()\n",
    "    feat_cols = []\n",
    "    for i in range(rfe_support.size):\n",
    "        if rfe_support[i]:\n",
    "            feat_cols.append(i)\n",
    "    X_train = X_features_train[:, feat_cols]\n",
    "    X_test = X_features_test[:, feat_cols]\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    resDT.append(clf.score(X_test, y_test))\n",
    "    \n",
    "    rfe_selector = RFE(estimator = LDA(), n_features_to_select = i, step = 1)\n",
    "    rfe_selector.fit(X_features_train, y_train)\n",
    "    rfe_support = rfe_selector.get_support()\n",
    "    feat_cols = []\n",
    "    for i in range(rfe_support.size):\n",
    "        if rfe_support[i]:\n",
    "            feat_cols.append(i)\n",
    "    X_train = X_features_train[:, feat_cols]\n",
    "    X_test = X_features_test[:, feat_cols]\n",
    "    \n",
    "    clf = LDA()\n",
    "    clf.fit(X_train, y_train)\n",
    "    resLDA.append(clf.score(X_test, y_test))\n",
    "    \n",
    "print(\"DT:\", resDT)\n",
    "print(\"LDA:\", resLDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [0, 1, 2, 4, 11, 14, 15, 16, 20, 22, 24, 26, 28, 29, 32, 40, 41, 42, 51]\n",
    "X_train = X_features_train[:, feat_cols]\n",
    "X_test = X_features_test[:, feat_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MusJ3e-VmuLg"
   },
   "source": [
    "## Choosing only best features\n",
    " take only best features set to feed to models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "M1ptYtsStUAK",
    "outputId": "578a24b1-8e3e-41b8-d95d-269994447a8c"
   },
   "outputs": [],
   "source": [
    "feat_cols = [0, 1, 3, 4, 5, 9, 14, 15, 16, 20, 26, 27, 28, 29, 39, 40, 41, 42, 48]\n",
    "X_train = X_features_train[:, feat_cols]\n",
    "X_test = X_features_test[:, feat_cols]\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "print(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HUiJclaRGLOZ",
    "outputId": "cd092b7b-b6da-47b9-b758-c9314bb24575"
   },
   "outputs": [],
   "source": [
    "## grid search for SVM classifier\n",
    "clf = SVC()\n",
    "\n",
    "params_grid = {\"kernel\":[\"rbf\"],\n",
    "               \"gamma\": [1e-2, 1e-1, 3e-1, 5e-1, 7e-1],\n",
    "               \"C\":[10, 100, 1000]}\n",
    "gs = GridSearchCV(clf, param_grid = params_grid, scoring = \"accuracy\", cv = 10)\n",
    "gs.fit(X_train, y_train)\n",
    "for i in range(len(gs.cv_results_['params'])):\n",
    "    print(gs.cv_results_['params'][i], 'test acc.:', gs.cv_results_['mean_test_score'][i])\n",
    "\n",
    "print(\"Best parameters via GridSearch\", gs.best_params_)\n",
    "print(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "gFa5iGg6_Q-M",
    "outputId": "24fe4f75-4a83-4cc9-ddf2-55dfdefb0e24"
   },
   "outputs": [],
   "source": [
    "## save SVM grid search results\n",
    "df = pd.DataFrame.from_dict(gs.cv_results_, orient=\"index\")\n",
    "df.head()\n",
    "result_dir = os.path.join(root, results_fold)\n",
    "if mode == 'Forward':\n",
    "    csv_name = f'Classifier/stratify-split-SFFS-{total_features}-{n_features}-features-SVM-gridsearchcv.csv'\n",
    "else:\n",
    "    csv_name = f'Classifier/stratify-split-SBFS-{total_features}-{n_features}-features-SVM-gridsearchcv.csv'\n",
    "print(\"SFAs mode: \", mode)\n",
    "df.to_csv(os.path.join(result_dir, csv_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "50zYLJ9hyznx",
    "outputId": "53321715-ef83-44e0-ae69-10a7d15f43bf"
   },
   "outputs": [],
   "source": [
    "print(\"overlap\", overlap)\n",
    "C_param = np.arange(100, 1100, 100)\n",
    "b = [0.1, 1, 10, 10000]\n",
    "C_param = np.append(C_param, b)\n",
    "print(C_param)\n",
    "gamma_param = np.arange(0.1, 2.6, 0.1)\n",
    "best_res = [0,0,0]\n",
    "\n",
    "for C in C_param:\n",
    "    for gamma in gamma_param:\n",
    "        clf = SVC(kernel = 'rbf', C = C, gamma = gamma);\n",
    "        clf.fit(X_train, y_train)\n",
    "        temp = clf.score(X_test, y_test)\n",
    "        if ( temp > best_res[0]):\n",
    "            best_res = [temp, C, gamma]\n",
    "print(\"Best res:\", best_res)\n",
    "\n",
    "clf = SVC(kernel = 'rbf', C = best_res[1], gamma = best_res[2])\n",
    "# clf = SVC(kernel = 'rbf', C = 500, gamma = 0.1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "CM = confusion_matrix(y_test, clf.predict(X_test))\n",
    "\n",
    "fig = plot_confusion_matrix(cm  = CM,\n",
    "                      normalize    = None,\n",
    "                      target_names = emotion_keys,\n",
    "                      title        = \"Confusion Matrix - Overlapped data- SVM\",\n",
    "                      savefig = True,\n",
    "                      figname = \"SVM-overlapped-confusionmatrix - both.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "I5kMouZqRfr5",
    "outputId": "e41cf12b-764e-4336-8b89-39a2602bcef4"
   },
   "outputs": [],
   "source": [
    "# Softmax classifier\n",
    "clf = LogisticRegression(random_state=1, solver='lbfgs', multi_class='multinomial')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(confusion_matrix(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "ZIR2Bs5lM1Cx",
    "outputId": "aa504bc2-dc31-4ca1-d136-f87ce2b45cc2"
   },
   "outputs": [],
   "source": [
    "# KNN classifier\n",
    "clf = KNeighborsClassifier(n_neighbors= 1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_test, y_test))\n",
    "print(confusion_matrix(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "CM = confusion_matrix(y_test, clf.predict(X_test))\n",
    "\n",
    "print(clf.score(X_test, y_test))\n",
    "print(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fAt8btYN8xJw"
   },
   "source": [
    "# Random forest classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 604
    },
    "colab_type": "code",
    "id": "aBQlpzjz8xJy",
    "outputId": "16cdb8e8-d25e-48c3-cc5a-8733b450d2bb"
   },
   "outputs": [],
   "source": [
    "# search params for RF classifier using grid search\n",
    "# Create the parameter grid \n",
    "param_grid = {\n",
    "    'n_estimators'      : [64, 100, 200, 300, 400, 500, 600],\n",
    "    'max_depth'         : [30, 40, 50, 100],\n",
    "    'random_state'      : [0],\n",
    "    #'max_features': ['auto'],\n",
    "    #'criterion' :['gini']\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "gs = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)\n",
    "gs.fit(X_train, y_train)   \n",
    "\n",
    "for i in range(len(gs.cv_results_['params'])):\n",
    "    print(gs.cv_results_['params'][i], 'test acc.:', gs.cv_results_['mean_test_score'][i])\n",
    "\n",
    "print(\"Best parameters via GridSearch\", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8zLe-C58xJ4"
   },
   "outputs": [],
   "source": [
    "# save gridsearch result\n",
    "df = pd.DataFrame.from_dict(gs.cv_results_, orient=\"index\")\n",
    "df.head()\n",
    "result_dir = os.path.join(root, results_fold)\n",
    "csv_name = f'Classifier/stratify-split-{mode}-{total_features}-{n_features}-features-RF-gridsearchcv.csv'\n",
    "df.to_csv(os.path.join(result_dir, csv_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 651
    },
    "colab_type": "code",
    "id": "ZfZdcn3HSWSR",
    "outputId": "6fba6e4e-12c1-4fc8-e411-3417047d2d7d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"overlap\", overlap)\n",
    "n_param = np.arange(100, 1000, 100)\n",
    "depth_param = np.arange(20, 150, 10)\n",
    "best_res = [0,0,0]\n",
    "for n in n_param:\n",
    "    for depth in depth_param:\n",
    "        clf = RandomForestClassifier(random_state = 0, n_estimators = n, max_depth = depth);\n",
    "        clf.fit(X_train, y_train)\n",
    "        temp = clf.score(X_test, y_test)\n",
    "        if ( temp > best_res[0]):\n",
    "            best_res = [temp, n, depth]\n",
    "print(\"Best res: \", best_res)\n",
    "\n",
    "clf = RandomForestClassifier(random_state = 0, n_estimators = best_res[1], max_depth = best_res[2])\n",
    "# clf = RandomForestClassifier(random_state = 0, n_estimators = 400, max_depth = 20)\n",
    "clf.fit(X_train, y_train)\n",
    "CM = confusion_matrix(y_test, clf.predict(X_test))\n",
    "\n",
    "fig = plot_confusion_matrix(cm  = CM,\n",
    "                      normalize    = None,\n",
    "                      target_names = emotion_keys,\n",
    "                      title        = \"Confusion Matrix - Overlapped data- RandomForest\",\n",
    "                      savefig = True,\n",
    "                      figname = \"Random Forest confusion matrix-both.png\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "eKpNoQPTSxPd",
    "scdHRgLxSxPp",
    "jchLoebaMMph"
   ],
   "name": "Neural_7s_overlapped_segmenting_method.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
