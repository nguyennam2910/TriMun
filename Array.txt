*SVM:
No emo = [16, 17, 18, 19, 18, 19, 20, 18, 18, 18]
Anger =  [17, 17, 16, 17, 17, 16, 17, 18, 16, 19]
Hate =   [16, 16, 18, 13, 17, 18, 13, 15, 17, 16]
Grief =  [11, 11, 14, 14, 15, 13, 12, 15, 16, 16]
P-love = [14, 15, 15, 16, 15, 13, 18, 14, 19, 16]
R-love = [15, 14, 11, 15, 13, 14, 16, 15, 14, 15]
Joy =    [9, 11, 13, 14, 13, 15, 14, 15, 14, 15]
Rever =  [17, 17, 17, 17, 18, 18, 16, 18, 17, 19]

*RandomForest:
No emo = [18, 18, 16, 17, 18, 19, 18, 18, 19, 18]
Anger =  [17, 17, 18, 17, 19, 17, 17, 17, 19, 18]
Hate =   [15, 15, 17, 12, 17, 14, 15, 16, 17, 18]
Grief =  [14, 13, 13, 14, 14, 15, 14, 14, 14, 16]
P-love = [14, 14, 13, 17, 15, 15, 16, 16, 16, 17]
R-love = [13, 13, 12, 15, 9, 13, 13, 15, 15, 17]
Joy =    [11, 12, 15, 13, 14, 15, 15, 15, 14, 14]
Revere = [18, 19, 18, 19, 20, 19, 19, 20, 20, 20]

0%
SVM: [0.2125, 0.25625, 0.425, 0.53125, 0.54375, 0.63125, 0.65, 0.6625, 0.68125, 0.68125, 0.725, 0.74375, 0.73125, 0.74375, 0.725, 0.78125, 0.7875, 0.76875, 0.7375, 0.74375, 0.7625, 0.6875, 0.70625, 0.7125, 0.70625, 0.6875, 0.68125, 0.69375, 0.7, 0.7375, 0.7, 0.66875, 0.7, 0.65625, 0.675, 0.625, 0.59375, 0.63125, 0.58125, 0.6, 0.60625, 0.63125, 0.63125, 0.61875, 0.60625, 0.5875, 0.56875, 0.575, 0.59375, 0.59375, 0.5875, 0.5875]

RF: [0.13125, 0.3625, 0.675, 0.74375, 0.6625, 0.725, 0.73125, 0.79375, 0.75625, 0.7625, 0.7875, 0.73125, 0.79375, 0.74375, 0.76875, 0.76875, 0.71875, 0.79375, 0.775, 0.7875, 0.78125, 0.8, 0.8, 0.775, 0.79375, 0.7875, 0.79375, 0.76875, 0.7625, 0.78125, 0.7875, 0.7875, 0.79375, 0.775, 0.775, 0.7625, 0.76875, 0.78125, 0.78125, 0.7875, 0.78125, 0.7625, 0.78125, 0.7625, 0.75625, 0.76875, 0.7625, 0.75, 0.7375, 0.70625, 0.76875, 0.75625]

0% default param

SVM: [0.2125, 0.29375, 0.3375, 0.35625, 0.43125, 0.43125, 0.40625, 0.4125, 0.40625, 0.40625, 0.43125, 0.4375, 0.45625, 0.46875, 0.45, 0.4625, 0.4625, 0.4625, 0.45625, 0.475, 0.45625, 0.48125, 0.48125, 0.4875, 0.50625, 0.49375, 0.49375, 0.49375, 0.46875, 0.475, 0.49375, 0.48125, 0.4875, 0.475, 0.4875, 0.49375, 0.48125, 0.48125, 0.48125, 0.5125, 0.50625, 0.49375, 0.50625, 0.4875, 0.4875, 0.48125, 0.4875, 0.48125, 0.4875, 0.4875, 0.48125, 0.4875]

RF: [0.13125, 0.30625, 0.66875, 0.54375, 0.69375, 0.6875, 0.7125, 0.75625, 0.74375, 0.75, 0.725, 0.8, 0.725, 0.71875, 0.75, 0.76875, 0.75625, 0.76875, 0.78125, 0.775, 0.775, 0.7625, 0.74375, 0.75, 0.78125, 0.74375, 0.775, 0.76875, 0.78125, 0.7625, 0.79375, 0.76875, 0.775, 0.76875, 0.7625, 0.7375, 0.76875, 0.7875, 0.71875, 0.75625, 0.74375, 0.74375, 0.75, 0.7375, 0.79375, 0.7375, 0.75, 0.74375, 0.71875, 0.7375, 0.7125, 0.75625]

DT: [0.225, 0.43125, 0.54375, 0.475, 0.5, 0.5125, 0.5375, 0.525, 0.53125, 0.48125, 0.5625, 0.53125, 0.5625, 0.51875, 0.5625, 0.53125, 0.5375, 0.4875, 0.56875, 0.6, 0.5375, 0.525, 0.575, 0.525, 0.5625, 0.5125, 0.54375, 0.55625, 0.5875, 0.5125, 0.55625, 0.45625, 0.53125, 0.5625, 0.5, 0.5375, 0.5, 0.53125, 0.55625, 0.54375, 0.5625, 0.5125, 0.5375, 0.5, 0.5, 0.49375, 0.525, 0.5, 0.5, 0.46875, 0.50625, 0.50625]

LDA: [0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875, 0.46875]

10% no tuning param

SVM: [0.23125, 0.20625, 0.3, 0.35625, 0.41875, 0.41875, 0.40625, 0.43125, 0.4, 0.4125, 0.43125, 0.43125, 0.4375, 0.425, 0.4375, 0.46875, 0.46875, 0.475, 0.4625, 0.4875, 0.4625, 0.49375, 0.48125, 0.48125, 0.48125, 0.49375, 0.5125, 0.4875, 0.475, 0.50625, 0.5125, 0.475, 0.50625, 0.525, 0.53125, 0.5375, 0.53125, 0.55, 0.53125, 0.54375, 0.5375, 0.5375, 0.55, 0.53125, 0.54375, 0.525, 0.54375, 0.53125, 0.55625, 0.55625, 0.5375, 0.5375]
RF: [0.18125, 0.29375, 0.525, 0.56875, 0.6375, 0.68125, 0.675, 0.65, 0.6375, 0.7125, 0.70625, 0.7, 0.7, 0.69375, 0.75625, 0.71875, 0.70625, 0.725, 0.74375, 0.7375, 0.75, 0.73125, 0.70625, 0.74375, 0.75625, 0.675, 0.7, 0.70625, 0.73125, 0.73125, 0.7375, 0.725, 0.70625, 0.71875, 0.69375, 0.73125, 0.7125, 0.7125, 0.6875, 0.74375, 0.69375, 0.70625, 0.70625, 0.725, 0.69375, 0.725, 0.6875, 0.7375, 0.71875, 0.66875, 0.71875, 0.68125]

70%
SVM: [0.18125, 0.34375, 0.4625, 0.6, 0.56875, 0.65, 0.66875, 0.70625, 0.73125, 0.78125, 0.7625, 0.79375, 0.79375, 0.73125, 0.79375, 0.7875, 0.80625, 0.75625, 0.75625, 0.76875, 0.7625, 0.775, 0.7875, 0.7625, 0.73125, 0.75, 0.75625, 0.7375, 0.69375, 0.70625, 0.68125, 0.71875, 0.7125, 0.75, 0.75, 0.74375, 0.73125, 0.725, 0.7, 0.70625, 0.71875, 0.66875, 0.675, 0.675, 0.675, 0.7, 0.7125, 0.7125, 0.65625, 0.66875, 0.66875, 0.66875]

RF: [0.3, 0.45, 0.59375, 0.7625, 0.75625, 0.75625, 0.78125, 0.79375, 0.76875, 0.8, 0.78125, 0.80625, 0.775, 0.7625, 0.75, 0.8, 0.78125, 0.7625, 0.7625, 0.7625, 0.78125, 0.75625, 0.7875, 0.78125, 0.75, 0.7625, 0.7875, 0.7875, 0.75, 0.76875, 0.7625, 0.775, 0.75, 0.75625, 0.775, 0.75625, 0.75, 0.775, 0.76875, 0.75625, 0.775, 0.78125, 0.78125, 0.75, 0.8, 0.75625, 0.775, 0.75625, 0.75, 0.775, 0.75, 0.7625]

https://www.upgrad.com/blog/random-forest-vs-decision-tree/#:~:text=A%20decision%20tree%20combines%20some,forest%20model%20needs%20rigorous%20training.
https://towardsdatascience.com/decision-trees-explained-3ec41632ceb6
https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html#:~:text=Decision%20trees%20use%20multiple%20algorithms,homogeneity%20of%20resultant%20sub%2Dnodes.&text=The%20decision%20tree%20splits%20the,in%20most%20homogeneous%20sub%2Dnodes.
https://builtin.com/data-science/random-forest-algorithm